{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a8eed7",
   "metadata": {},
   "source": [
    "# Script for 2025 Nextflow Microbiome Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12322858",
   "metadata": {},
   "source": [
    "## Sol login and Fastq file upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b307bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you copy the files to your home directory on sol. You can access the interactive Sol browser at with the link below:\n",
    "# Sol --> https://ood05.sol.rc.asu.edu/pun/sys/dashboard/ \n",
    "\n",
    "# You can also use scp or rsync \n",
    "# Here is an example: \n",
    "# rsync -P *.fastq (ASURITE USERNAME)@login.sol.rc.asu.edu:/home/[ASURITE USERNAME]\n",
    "\n",
    "# it is recommended you create a folder for storing all of the pipelines results. You can create directories by running the following command while logged into Sol:\n",
    "# mkdir nextflow_pacbio_2025_workshop\n",
    "\n",
    "# login into sol with the following: \n",
    "# ssh (ASURITE USERNAME)@login.sol.rc.asu.edu\n",
    "\n",
    "# if having difficulties connecting, or need to connect to sol while off campus, please see the ASU Supercomputing Wiki:\n",
    "# Connecting to Sol --> https://asurc.atlassian.net/wiki/spaces/RC/pages/1905131521/Connecting+to+the+Supercomputers+with+SSH\n",
    "# Transferrring Files to a Supercomputer --> https://asurc.atlassian.net/wiki/spaces/RC/pages/1852670115/Transferring+Files+to+a+Supercomputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the workshop github, there are two important files provided if running the nextflow pipeline included at the end of the workshop script: \n",
    "# workshop_metadata.tsv and workshop_samplelist.tsv\n",
    "\n",
    "# Before running the pipeline, open the workshop_samplelist.tsv document and ensure that the filepaths for the fastq files map\n",
    "# to where they are on your Sol account. Nextflow is picky about the column names, and extra \"lines\" in the samplelist\n",
    "# will cause the pipeline to fail at startup. Good first place to check for debugging! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d96c7",
   "metadata": {},
   "source": [
    "## FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcd86c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# We will first assess the quality of the data using fastqc ls\n",
    "# Fastqc is installed on Sol, and publically available through modules\n",
    "# To access it, we can use the code below\n",
    "module load fastqc-0.12.1-gcc-11.2.0\n",
    "\n",
    "# Navigate to the directory containing your fastq files\n",
    "# To run fastqc on one sample: \n",
    "fastqc mouse_1.fastq\n",
    "\n",
    "# To run fastqc on all fastq files in a directory \n",
    "fastqc *.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fff0c",
   "metadata": {},
   "source": [
    "## Seqkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4a220",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Use seqkit to gain more insights about the quality of the data \n",
    "\n",
    "# Use the following to install seqkit onto nextflow environment\n",
    "conda install bioconda::seqkit\n",
    "\n",
    "# Use seqkit stats \n",
    "seqkit stats -a *.fastq > seqkit-stats.txt # open in excel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3384e2b",
   "metadata": {},
   "source": [
    "## Create QIIME2 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c21c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to create a conda environment for the new QIIME2 environment\n",
    "\n",
    "wget https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2024.5-py39-linux-conda.yml\n",
    "\n",
    "# You may need to start an interactive session for this to work\n",
    "# example: interactive -c 4 --mem=48G\n",
    "conda env create -n qiime2-amplicon-2024.5 --file https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2024.5-py39-linux-conda.yml\n",
    "\n",
    "# Activate the environment\n",
    "source activate activate qiime2-amplicon-2024.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the following steps will need more RAM, we need to submit slurm batch scripts \n",
    "\n",
    "# First, update all filepaths in the below code to your workshop files stored on Sol\n",
    "# Then, copy the entire code below into a text file and save as run_nf.slurm\n",
    "\n",
    "# Submit the job\n",
    "sbatch run_nf.slurm\n",
    "\n",
    "# Check your job in the queue \n",
    "squeue -u ASURITEUSER\n",
    "\n",
    "# To cancel the job if something is wrong (replace 123456 with your job ID)\n",
    "scancel 123456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c3c10",
   "metadata": {},
   "source": [
    "## Import data into QIIME2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=one-import_fastq_files\n",
    "#SBATCH -o import_fastq.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 8:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=40G\n",
    "#SBATCH -p general\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Activate QIIME2 \n",
    "module load mamba/latest\n",
    "source activate qiime2-amplicon-2024.5\n",
    "\n",
    "# Import FASTQ FILES\n",
    "# You will need to make sure you include the manifest file for these samples\n",
    "qiime tools import \\\n",
    "  --type 'SampleData[SequencesWithQuality]' \\\n",
    "  --input-path manifest.txt \\\n",
    "  --input-format SingleEndFastqManifestPhred33V2 \\\n",
    "  --output-path pacbio-seqs.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0781ca",
   "metadata": {},
   "source": [
    "# Denoising the sequencing data \n",
    "\n",
    "Top code cell demonstrates DADA2 denoising for raw PacBio sequences\n",
    "\n",
    "The bottom code cell is what we will use today, since the primers for the PacBio sequence samples we are working with have already been trimmed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97674bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=denoise\n",
    "#SBATCH -o denoise.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 8:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=40G\n",
    "#SBATCH -p general\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Record the start time\n",
    "start_time=$(date)\n",
    "\n",
    "module load mamba/latest\n",
    "\n",
    "source activate QIIME2-amplicon-2024.5\n",
    "\n",
    "start_time=$(date)\n",
    "\n",
    "qiime dada2 denoise-ccs \\\n",
    "--i-demultiplexed-seqs pacbio-seqs.qza \\\n",
    "--p-trim-left 0 \\\n",
    "--p-trunc-len 0 \\\n",
    "--p-front AGRGTTYGATYMTGGCTCAG \\\n",
    "--p-adapter RGYTACCTTGTTACGACTT \\\n",
    "--o-representative-sequences rep-seqs.qza   \\\n",
    "--o-table table.qza   \\\n",
    "--o-denoising-stats stats.qza\n",
    "\n",
    "end_time=$(date +%s)\n",
    "\n",
    "runtime=$((end_time - start_time))\n",
    "\n",
    "echo \"Job complete\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=denoise\n",
    "#SBATCH -o denoise.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 8:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=40G\n",
    "#SBATCH -p general\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Record the start time\n",
    "start_time=$(date)\n",
    "\n",
    "module load mamba/latest\n",
    "\n",
    "source activate QIIME2-amplicon-2024.5\n",
    "\n",
    "start_time=$(date)\n",
    "\n",
    "qiime dada2 denoise-single \\\n",
    "  --i-demultiplexed-seqs pacbio-seqs.qza \\\n",
    "  --p-trunc-len 0 \\\n",
    "  --p-trim-left 0 \\\n",
    "  --o-representative-sequences rep-seqs.qza \\\n",
    "  --o-table table.qza \\\n",
    "  --o-denoising-stats stats.qza\n",
    "\n",
    "end_time=$(date +%s)\n",
    "\n",
    "runtime=$((end_time - start_time))\n",
    "\n",
    "echo \"Job complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5bc68",
   "metadata": {},
   "source": [
    "## Download Greengenes2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the greengenes2 database \n",
    "wget --no-check-certificate https://ftp.microbio.me/greengenes_release/2024.09/2024.09.backbone.full-length.fna.qza\n",
    "\n",
    "# For the taxonomy file\n",
    "wget --no-check-certificate https://ftp.microbio.me/greengenes_release/2024.09/2024.09.backbone.tax.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9813c4f7",
   "metadata": {},
   "source": [
    "## Classify with Vsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1380c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=classify\n",
    "#SBATCH -o classify.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 4:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=40G\n",
    "#SBATCH -p general\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Record the start time\n",
    "start_time=$(date)\n",
    "\n",
    "module load mamba/latest\n",
    "\n",
    "source activate QIIME2-amplicon-2024.5\n",
    "\n",
    "qiime feature-classifier classify-consensus-vsearch \\\n",
    "    --i-query rep-seqs.qza \\\n",
    "    --i-reference-reads 2024.09.backbone.full-length.fna.qza  \\\n",
    "    --i-reference-taxonomy 2024.09.backbone.tax.qza  \\\n",
    "    --p-maxaccepts 1 --p-strand \"plus\" \\\n",
    "    --p-threads 4 \\\n",
    "    --verbose \\\n",
    "    --output-dir taxa\n",
    "\n",
    "qiime tools export --input-path taxa/classification.qza --output-path taxa\n",
    "\n",
    "echo \"Job complete\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1be01",
   "metadata": {},
   "source": [
    "### Analyses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497868f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert taxonomy.tsv file to taxonomy.qza file\n",
    "qiime tools import \\\n",
    "  --type 'FeatureData[Taxonomy]' \\\n",
    "  --input-format HeaderlessTSVTaxonomyFormat \\\n",
    "  --input-path taxonomy.tsv \\\n",
    "  --output-path taxonomy.qza\n",
    "\n",
    "# change the header from Feature ID to feature-id\n",
    "# run the following to check the file\n",
    "# qiime metadata tabulate --m-input-file taxonomy.qza --o-visualization taxonomy.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a968c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a barplot\n",
    "\n",
    "qiime taxa barplot \\\n",
    "--i-table table.qza \\\n",
    "--i-taxonomy taxa/taxonomy.qza \\\n",
    "--m-metadata-file workshop_metadata.tsv \\\n",
    "--o-visualization taxa-bar-plots.qzv\n",
    "\n",
    "# used qiime taxa barplot --i-table table.qza --i-taxonomy taxa/classification.qza --m-metadata-file workshop_metadata.tsv --o-visualization taxa-bar-plots.qzv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39692b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=denoise\n",
    "#SBATCH -o denoise.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 4:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# collapse table to the genus level \n",
    "qiime taxa collapse --i-table table.qza \\\n",
    "--i-taxonomy taxa/taxonomy.qza \\\n",
    "--p-level 6 \\\n",
    "--o-collapsed-table genus-table.qza\n",
    "\n",
    "qiime taxa collapse --i-table table.qza \\\n",
    "--i-taxonomy taxa/taxonomy.qza \\\n",
    "--p-level 6 \\\n",
    "--o-collapsed-table genus-table-2.qza\n",
    "\n",
    "qiime taxa collapse --i-table table.qza \\\n",
    "--i-taxonomy taxa/taxonomy.qza \\\n",
    "--p-level 7 \\\n",
    "--o-collapsed-table species-table.qza\n",
    "\n",
    "qiime taxa collapse --i-table table.qza \\\n",
    "--i-taxonomy taxa/taxonomy.qza \\\n",
    "--p-level 2 \\\n",
    "--o-collapsed-table phylum-table.qza\n",
    "\n",
    "echo \"Job complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the table from a QZA format to a BIOM or txt format \n",
    "# Note that both of these files can be inputted into other programs \n",
    "\n",
    "qiime tools export --input-path genus-table.qza --output-path genus-analysis-2\n",
    "biom convert -i genus-analysis/feature-table.biom -o genus-analysis/feature-table.txt --to-tsv\n",
    "\n",
    "qiime tools export --input-path species-table.qza --output-path species-analysis\n",
    "biom convert -i species-analysis/feature-table.biom -o species-analysis/feature-table.txt --to-tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to remove singletons and rare taxa that may be inflating diversity estimates and are present due to spurious mappings \n",
    "\n",
    "qiime feature-table filter-features \\\n",
    "  --i-table genus-table-2.qza \\\n",
    "  --p-min-samples 2 \\\n",
    "  --p-min-frequency 10 \\\n",
    "  --o-filtered-table filtered-genus-table.qza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b0583",
   "metadata": {},
   "source": [
    "## Compositional analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d07102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install gemelli\n",
    "# make sure your QIIME2 environment is active \n",
    "pip install gemelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Aitchison distance matrix \n",
    "\n",
    "qiime gemelli rpca \\\n",
    "--i-table genus-table.qza \\\n",
    "--o-biplot genus-table-ordination.qza \\\n",
    "--o-distance-matrix genus-table-distance.qza\n",
    "\n",
    "qiime emperor biplot \\\n",
    "--i-biplot genus-table-ordination.qza \\\n",
    "--m-sample-metadata-file metadata.txt \\\n",
    "--o-visualization genus-biplot.qzv \\\n",
    "--p-number-of-features 1\n",
    "    \n",
    "# PERMANOVA results \n",
    "\n",
    "NAME=genus\n",
    "METADATA=metadata.txt\n",
    "declare -a StringArray=(\"GroupNumber\" \"Health\")\n",
    "for category in ${StringArray[@]}; do\n",
    "qiime diversity beta-group-significance \\\n",
    "  --i-distance-matrix genus-table-distance.qza \\\n",
    "  --m-metadata-file $METADATA \\\n",
    "  --m-metadata-column \"$category\" \\\n",
    "  --o-visualization ${NAME}-$category-significance.qzv \\\n",
    "  --p-pairwise\n",
    "done\n",
    "\n",
    "qiime diversity adonis \\\n",
    "--i-distance-matrix genus-table-distance.qza \\\n",
    "--m-metadata-file $METADATA \\\n",
    "--p-formula \"GroupNumber*Health\" \\\n",
    "--o-visualization adonis-${NAME}.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2873cbf",
   "metadata": {},
   "source": [
    "## Alpha diversity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC=observed_features\n",
    "qiime diversity alpha \\\n",
    "--i-table genus-table.qza \\\n",
    "--p-metric $METRIC \\\n",
    "--o-alpha-diversity alpha-${NAME}-${METRIC}.qza\n",
    "\n",
    "qiime diversity alpha-group-significance\n",
    "--i-alpha-diversity alpha-${NAME}-${METRIC}.qza\n",
    "--m-metadata-file $METADATA\n",
    "--o-visualization alpha-${NAME}-${METRIC}.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebe580",
   "metadata": {},
   "source": [
    "Additional commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d28440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obc2dfatq command\n",
    "\n",
    "obc2fastq --input <run folder> \\\n",
    "--output <output folder name> \\\n",
    "--flowcellid <flow cell ID> \\\n",
    "--samplesheet <sampleSheet.csv file name> \\\n",
    "--designsheet <obc2fastq_params file name> \\\n",
    "--threadlanes <int> \\--threadsperlane <int> \\\n",
    "--controlsfile <control fasta file name> \\\n",
    "--barcodeallowedmismatches <int> \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1895f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the fastq files to make them smaller \n",
    "# Good when you want to just test whether your program is working without having to do it on the entire dataset\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name=denoise\n",
    "#SBATCH -o denoise.out\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 4:00:00\n",
    "#SBATCH --cpus-per-task=10\n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Record the start time\n",
    "start_time=$(date)\n",
    "\n",
    "module load mamba/latest\n",
    "\n",
    "source activate FASTQ_PROCESSING\n",
    "\n",
    "ls SRR2338099*.fastq | while read samples; do\n",
    "    base_name=$(basename \"$samples\" .fastq)  # Extract the base name without .fastq\n",
    "    seqkit sample -p 0.4 \"$samples\" -o \"${base_name}.4.fastq\"  # Use the base name for output\n",
    "done\n",
    "\n",
    "# -p is for proportion of sequences to subsample to; here we are collecting 40% of sequences\n",
    "\n",
    "echo \"Job Complete\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1cc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are having trouble with DEICODE, you may need to downgrade your numpy environment\n",
    "# Make sure your conda environment for QIIME2 is active conda \n",
    "mamba install numpy=1.19.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d57db",
   "metadata": {},
   "source": [
    "## Create Nextflow conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741afcc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# We will need to create a conda environment for the nextflow pipeline environment\n",
    "\n",
    "# First, request an interactive environment while logged into sol (navigate to \"System\" then \"Sol Shell Access\" if on Sol web browser)  \n",
    "interactive -c 4 --mem=48G\n",
    "\n",
    "# We then load the mamba module, and create a new conda environment for nextflow. \n",
    "module load mamba/latest\n",
    "conda create -n nextflow -c bioconda -c conda-forge nextflow\n",
    "\n",
    "# Activate the new environment\n",
    "source activate nextflow\n",
    "\n",
    "# Confirm Nextflow was corretly installed\n",
    "nextflow info\n",
    "\n",
    "# To update Nextflow, run:\n",
    "nextflow self-update\n",
    "\n",
    "# After installing Nextflow, we have to download the alignment databases using the following commands. \n",
    "# To update the pipeline in the future, type \"git pull\" instead of \"git clone\".\n",
    "# This will take awhile to download, please download these prior to the workshop. (Took around ~35 mins when testing)\n",
    "git clone https://github.com/PacificBiosciences/HiFi-16S-workflow.git\n",
    "cd HiFi-16S-workflow\n",
    "nextflow run main.nf --download_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6967eea",
   "metadata": {},
   "source": [
    "## Running the Nextflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f28d3a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -J nextflow-pb16s\n",
    "#SBATCH -p general\n",
    "#SBATCH -N 1\n",
    "#SBATCH -c 32\n",
    "#SBATCH --mem=128G\n",
    "#SBATCH -t 8:00:00\n",
    "#SBATCH -o logs/%x_%j.out\n",
    "#SBATCH -e logs/%x_%j.err\n",
    "#SBATCH --export=NONE\n",
    "\n",
    "# change directory where we submitted the slurm job\n",
    "cd \"$SLURM_SUBMIT_DIR\"\n",
    "\n",
    "set -uex\n",
    "\n",
    "# Record start time\n",
    "start_time=$(date)\n",
    "\n",
    "# Load Modules \n",
    "module load mamba/latest\n",
    "\n",
    "# Activate nextflow environment\n",
    "source activate nextflow\n",
    "\n",
    "# Metadeta and Sample list inputs. Ensure these match where you uploaded your files on sol\n",
    "SAMPLELIST=\"/home/**ASURITE USERNAME**/nextflow_pacbio_2025_workshop/workshop_samplelist.tsv\"\n",
    "METADATA=\"/home/**ASURITE USERNAME**/nextflow_pacbio_2025_workshop/workshop_metadata.tsv\"\n",
    "\n",
    "# Set the directory where you want your nextflow results to go. \n",
    "RESULTS_DIR=\"/home/**ASURITE USERNAME**/nextflow_pacbio_2025_workshop/results\"\n",
    "\n",
    "# Automatically makes a \"error logs\" folder for to store nextflow run and error logs. \n",
    "mkdir -p \"$RESULTS_DIR\" \"logs\"\n",
    "\n",
    "# Run a basic Nextflow workflow\n",
    "nextflow run /home/**ASURITE USERNAME**/HiFi-16S-workflow/main.nf \\\n",
    "  --input \"$SAMPLELIST\" \\\n",
    "  --metadata \"$METADATA\" \\\n",
    "  --min_len 900 \\\n",
    "  --max_len 1700 \\\n",
    "  --dada2_cpu 32 \\\n",
    "  --vsearch_cpu 32 \\\n",
    "  -resume\n",
    "\n",
    "# there are other possible inclusions for the pipeline, such as:\n",
    "# --run_picrust2 \\        --> runs a picrust2 analysis in the pipeline. \n",
    "# --rarefaction_depth \\   --> Rarefaction curve \"max-depth\" parameter. (automatically determined by default)\n",
    "# --front_p    Forward primer sequence.\n",
    "# --adapter_p    Reverse primer sequence.\n",
    "\n",
    "# for the full list of nextflow options, type:\n",
    "# nextflow run main.nf --help           \n",
    "\n",
    "# Record end time   \n",
    "end_time=$(date)\n",
    "\n",
    "# Indicate the pipeline has finished the analysis. \n",
    "echo \"Start Time: $start_time\"\n",
    "echo \"End Time: $end_time\"\n",
    "echo \"Job Complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b86a6",
   "metadata": {},
   "source": [
    "## Understanding Your PacBio HiFi 16S Nextflow Outputs\n",
    "\n",
    "When the HiFi-16S Nextflow pipeline finishes, you’ll have a directory of outputs (we called it `RESULTS_DIR` in the Slurm script).  \n",
    "Here’s a practical guide to what the main files/folders contain and how you might use them.\n",
    "\n",
    "## PacBio HiFi 16S Nextflow Pipeline Outputs\n",
    "\n",
    "### Feature Table & Sample Data  \n",
    "**Directory:** `tables/`\n",
    "\n",
    "- **feature_table.qza** or **table.qza**  \n",
    "  QIIME 2 feature table (ASV table).  \n",
    "  Rows = ASVs, columns = samples, values = counts.\n",
    "\n",
    "- **rarefied_table.qza**  \n",
    "  Feature table rarefied to an even sequencing depth.  \n",
    "  Used for alpha and beta diversity analyses.\n",
    "\n",
    "\n",
    "### Representative Sequences (ASVs)  \n",
    "**Directory:** `dada2/` or `tables/`\n",
    "\n",
    "- **rep_seqs.qza** or **rep_seqs_denoised.qza**  \n",
    "  Representative ASV sequences in FASTA format (one sequence per feature ID).  \n",
    "  Used for taxonomy assignment, phylogenetic tree building, and downstream sequence analyses.\n",
    "\n",
    "### Taxonomy Assignments  \n",
    "**Directory:** `taxonomy/`\n",
    "\n",
    "- **taxonomy.qza**  \n",
    "  QIIME 2 artifact mapping ASV IDs to taxonomic classifications.\n",
    "\n",
    "- **taxonomy.qzv**  \n",
    "  QIIME 2 visualization of taxonomic composition (bar plots, metadata grouping, etc.).\n",
    "\n",
    "\n",
    "### Phylogenetic Tree  \n",
    "**Directory:** `phylogeny/`\n",
    "\n",
    "- **aligned_rep_seqs.qza**  \n",
    "  Multiple sequence alignment of representative ASVs (e.g., MAFFT).\n",
    "\n",
    "- **phylogeny_unrooted.qza**  \n",
    "  Unrooted phylogenetic tree built from aligned ASVs.\n",
    "\n",
    "- **phylotree_mafft_rooted.qza** or **phylogeny_rooted.qza**  \n",
    "  Rooted phylogenetic tree required for phylogeny-based metrics (Faith’s PD, Weighted/Unweighted UniFrac).\n",
    "\n",
    "\n",
    "### Quality Control & Read Statistics  \n",
    "**Directory:** `qc/`\n",
    "\n",
    "- Per-sample QC summaries (HTML/TSV/PNG).  \n",
    "  Includes read counts, filtering results, read length distributions, and error profiles.\n",
    "\n",
    "\n",
    "### Pipeline & Run Logs  \n",
    "**Directories:** `logs/` and/or `nextflow_reports/`\n",
    "\n",
    "- **nextflow.log** or **.nextflow.log**  \n",
    "  Main pipeline execution log.\n",
    "\n",
    "- **execution_report.html**  \n",
    "  Summary of pipeline tasks, resource usage, and performance.\n",
    "\n",
    "- **execution_timeline.html**  \n",
    "  Gantt-style timeline of process execution.\n",
    "\n",
    "- **execution_trace.txt**  \n",
    "  Tabular summary of CPU/memory/time usage for each process.\n",
    "\n",
    "\n",
    "### Functional Profiling (Optional, if `--run_picrust2` used)  \n",
    "**Directory:** `picrust2/`\n",
    "\n",
    "- KEGG Ortholog abundance tables  \n",
    "- Predicted pathway abundance tables  \n",
    "  (Outputs from PICRUSt2 functional prediction.)\n",
    "\n",
    "\n",
    "### Files Used in QIIME 2 Post-Analysis  \n",
    "**Used from Nextflow output or external files**\n",
    "\n",
    "- **rarefied_table.qza**  \n",
    "- **phylotree_mafft_rooted.qza**  \n",
    "- **sample_metadata.tsv** (external)  \n",
    "  Inputs for any downstream analysis including alpha/beta diversity, PERMANOVA, and visualization steps.\n",
    "\n",
    "\n",
    "## For differential abundance analysis\n",
    "I recommend Maaslin2 or Maaslin3. Unlike other differential abundance analysis, this tool has the capability of log transforming abudnances while also accounting for both fixed and random effects \n",
    "\n",
    "link: https://huttenhower.sph.harvard.edu/maaslin/\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
